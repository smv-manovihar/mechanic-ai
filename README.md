# MechanicAI ğŸš—ğŸ› ï¸

MechanicAI is a self-hostable platform that combines AI-powered vehicle diagnostics, chat-based user interaction, and spare parts management. Designed for privacy and efficiency, it leverages cutting-edge technologies to streamline the repair process and enhance user experience.

---

## ğŸš€ Features

### ğŸ§  Advanced AI-Powered Diagnostics

- **Multi-Role AI Workflow**: Utilizes a chain of AI models, including a Diagnoser, Title Generator, and Spare Parts Recommender, to deliver accurate and consistent diagnostics.
- **LLM Orchestration**: Powered by LangChain to manage interactions between multiple AI models.

### ğŸ”’ Secure and Persistent User Management

- **Authentication**: Secure login system with session management with appwrite.
- **Chat History**: Persistent chat logs allow users to revisit past diagnostics and track ongoing repairs.

### ğŸ› ï¸ Automated Spare Parts Integration

- **Custom Catalog**: Automatically links diagnostic results to a custom spare parts catalog for quick and efficient repairs.
- **AI Recommendations**: Suggests relevant spare parts based on diagnostic outcomes.

### ğŸ–¥ï¸ Self-Hosted AI Server

- **Privacy First**: Hosts the Llama 3.1 model locally using Ollama, ensuring data privacy and reducing reliance on external services.
- **Flask API**: Lightweight and efficient backend for managing AI interactions.

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: React.js for a dynamic and responsive user interface.
- **Backend**: Node.js and Express.js for API development and user management.
- **AI Server**: Flask and Ollama for hosting and managing the Llama 3.1 model.
- **AI Workflow**: LangChain for orchestrating multi-role AI interactions.
- **Database**: MongoDB for storing user data, chat histories, and spare parts information.

---

## ğŸ“‚ Project Structure

- **Frontend**: React-based UI for user interaction.
- **Backend**: Node.js and Express.js for handling API requests and managing user sessions.
- **AI Server**: Flask API integrated with Ollama for hosting the Llama 3.1 model.
- **Database**: MongoDB for secure and scalable data storage.

---

## ğŸ“– Getting Started

### Prerequisites

- Node.js
- Python
- MongoDB
- Ollama (for hosting Llama 3.1)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/smv-manovihar/mechanic-ai.git
   ```
2. Install dependencies:
   - Frontend:
     ```bash
     cd Frontend
     npm install
     ```
   - Backend:
     ```bash
     cd Middleware
     npm install
     ```
   - AI Server:
     ```bash
     cd Backend
     pip install -r requirements.txt
     ```

### Running the Application

1. Start the services:
   - Frontend:
     ```bash
     npm run dev
     ```
   - Backend:
     ```bash
     node src/app.js
     ```
   - AI Server:
     ```bash
     flask run
     ```
2. Open your browser and navigate to `http://localhost:3000`.

---

## ğŸ“š Key Highlights

- **Chained AI Models**: A seamless workflow between Diagnoser, Title Generator, and Spare Parts Recommender ensures accurate diagnostics and actionable insights.
- **Self-Hosted AI**: Run the Llama 3.1 model locally to maintain data privacy and reduce external dependencies.
- **Persistent Chat Logs**: Keep track of diagnostic sessions for better repair tracking and user experience.
- **Integrated Spare Parts Management**: Automatically connects diagnostics to a custom spare parts catalog, simplifying the repair process.

---

## ğŸ¤ Contributing

We welcome contributions! Feel free to fork the repository, create a new branch, and submit a pull request with your changes.

---
